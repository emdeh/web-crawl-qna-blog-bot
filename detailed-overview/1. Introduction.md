# Introduction
This project leverages natural language processing (NLP) techniques, Large Language Models (LLMs) and embeddings to create an intelligent question-answering system. 

Comprising two main scripts, `preprocess.py` and `app.py`, the project automates the collection of textual data from a specified website, processes this data to generate meaningful numerical representations (embeddings), and utilises these embeddings to provide contextually relevant answers to user queries.

### Credits

Based off **OpenAI's Web  Q&A with Embeddings tutorial**. Learn how to crawl your website and build a Q/A bot with the OpenAI API. You can find the full tutorial in the [OpenAI documentation](https://platform.openai.com/docs/tutorials/web-qa-embeddings).

## Data Collection and Preparation - `preprocess.py` 
`preprocess.py` crawls web pages within a specified domain and systematically navigates through the website, extracting text from each page it encounters. The collected text undergoes initial preprocessing to clean and organise the data, making it suitable for further analysis.

The script then employs OpenAI's API to generate embeddings for each piece of text. These embeddings capture the semantic essence of the text in a high-dimensional space, facilitating the identification of contextual similarities between different texts. The processed data, along with its embeddings, is saved for subsequent use, laying the groundwork for the question-answering capabilities of the system.

## Flask Application for Question Answering - `app.py`
With the data prepared, `app.py` serves as the interface between the user and the system's NLP engine. This script initiates a Flask web application, providing endpoints for users to submit their questions.

Upon receiving a query, the application leverages the previously generated embeddings to find the most relevant context within the collected data. It then formulates this context and the user's question as input for an OpenAI GPT model. 

The model, trained on vast amounts of text from the internet, generates an answer that reflects both the specific information contained in the crawled data and its understanding of the topic at large. The answer is then returned to the user through the web interface, completing the cycle of query and response.

## Integration and Workflow
The integration of `preprocess.py` and `app.py` creates a workflow that bridges web crawling and NLP-driven question answering. Initially, `preprocess.py` lays the foundation by collecting and preparing the data, which `app.py` subsequently utilises to offer real-time answers. This allows the system to provide answers that are not only contextually relevant but also deeply informed by the specific context of the targeted domain. Users interact with the system through a straightforward web interface, making complex NLP capabilities accessible to anyone with a question to ask.

## Use-cases
Together, these scripts leverage sophisticated machine learning capabilties to demonstrate  how existing data from websites can be harnessed to build powerful and interactive AI-driven ways to retrieve and discovery knowledge.

For example, the basic capabilities demonstrated in this project could be applied to create a contextually-aware chatbot on a website. 

### [Click to continue to Overview](./2.%20Overview.md)

### [Back to home](/README.md)