### Extract and return all hyperlinks.

```python
def get_hyperlinks(url):

    # Try to open the URL and read the HTML
    try:
        # Open the URL and read the HTML
        with urllib.request.urlopen(url) as response:

            # If the response is not HTML, return an empty list
            if not response.info().get('Content-Type').startswith("text/html"):
                return []

            # Decode the HTML
            html = response.read().decode('utf-8')
    except Exception as e:
        print(e)
        return []

    # Create the HTML Parser and then Parse the HTML to get hyperlinks
    parser = HyperlinkParser()
    parser.feed(html)

    return parser.hyperlinks
```

The `get_hyperlinks(url)` function will extract and return all hyperlinks from a webpage specified by its URL. It will:

**1. Open the URL:** The function starts by trying to open the specified URL using the `urlopen` method from the `urllib.request module`. This method attempts to access the webpage and returns a response object if successful.

**2. Handle Non-HTML Responses:** Once the URL is opened, the function checks the `Content-Type` of the response to ensure it is an HTML document. 

> This is important because the function is designed to parse HTML content, and other types of content (like images or PDF files) would not contain hyperlinks in the format expected. If the content type does not start with "**text/html**", indicating it's not an HTML document, the function returns an empty list, as there are no hyperlinks to extract.

**3. Read and Decode the HTML:** If the content type is HTML, the function reads the response body using the `read()` method, which returns the HTML content as a byte string. This byte string is then decoded to a regular string (assuming UTF-8 encoding), representing the HTML source code of the webpage.

**4. Parse the HTML for Hyperlinks:** With the HTML content now in a string format, the function creates an instance of the `HyperlinkParser` class defined earlier. This custom parser is an `HTMLParser` that specifically looks for `<a>` tags and extracts the URLs specified in their href attributes. The `feed()` method of the parser is called with the HTML content, which triggers the parsing process. As the parser encounters `<a>` tags, it collects the URLs of the hyperlinks they contain and stores them in its `hyperlinks` list attribute.

**5. Return the Extracted Hyperlinks:** After the HTML content has been fully parsed, the function returns the list of hyperlinks collected by the `HyperlinkParser` instance. This list contains the URLs of all hyperlinks found on the webpage, which can then be used for further processing.

**Error handling:** The function includes a `try-except` block to handle any exceptions that might occur during the process of opening the URL, reading the response, or parsing the HTML. Common issues could include network errors, invalid URLs, or server-side errors causing a non-200 response. If any exception is caught, the function prints the exception message and returns an empty list, indicating that no hyperlinks could be extracted due to an error.

### [Click to continue...](/detailed-overview/preprocess.py-documentation/3.%20Fetch%20and%20filter%20hyperlinks.md)

### [Go back to overview](/detailed-overview/3.%20Detailed%20overview.md)