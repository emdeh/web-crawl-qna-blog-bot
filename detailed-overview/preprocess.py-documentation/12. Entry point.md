# Entry point

This section of the code represents the entry point for executing the script when it's run as a standalone program. The `if __name__ == "__main__":` check is a common Python idiom used to determine if the script is being run directly by the interpreter as opposed to being imported as a module in another script.

```python
################################################################################
### Main Functionality
################################################################################

if __name__ == "__main__":
    crawl(full_url)
    generate_embeddings(df)
    print("Preprocessing complete. Embeddings are ready.")
```

Here's a breakdown of what happens within this block:

**Crawling Web Pages:** The script begins its execution by calling the `crawl(full_url)` function. This function is tasked with crawling web pages starting from the `full_url`, which was defined earlier in the script as the entry point URL for the web crawling process. The crawl function navigates through the website located at `full_url`, collecting text from the pages it visits and saving this text to files organized by domain. This process also involves creating a queue of URLs to visit, ensuring only new and relevant (same domain) URLs are followed, thereby systematically exploring the content of the website.

**Generating Embeddings:** After crawling and collecting text data, the script calls `generate_embeddings(df)`, which assumes that a DataFrame `df` has been prepared with the text data extracted during the crawling process. This function processes each piece of text in the DataFrame, generating numerical vector representations (embeddings) for each using OpenAI's API. These embeddings are then added to the DataFrame, enriching it with data that captures the semantic essence of the texts in a format that's conducive to various NLP tasks. The enhanced DataFrame is saved to a CSV file, making the embeddings accessible for future use without the need to recompute them.

**Completion Message:** Finally, the script prints a message, "Preprocessing complete. Embeddings are ready.", signaling the end of the preprocessing workflow. This message indicates that the script has successfully completed its main tasks of web crawling, text data collection, and embeddings generation, and that the data is now ready for further analysis or modeling.

**Significance**
This entry point encapsulates a complete workflow for data collection and preprocessing, specifically tailored for NLP applications. By automating the process of web crawling, text extraction, and embeddings generation, the script provides a streamlined pathway to prepare raw web content for advanced NLP tasks, such as semantic analysis, machine learning modeling, or information retrieval systems. 

The automated generation of embeddings, in particular, transforms the collected text into a form that's directly usable in data-driven NLP models, significantly reducing the manual effort required for data preparation and enabling more sophisticated analyses.

### [Click to continue to `app.py` detailed overview](/detailed-overview/app.py-documentation/1.%20Flask%20app%20initialisation.md)

### [Go back to overview](/detailed-overview/3.%20Detailed%20overview.md)